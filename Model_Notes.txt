
Notes on Model development, Training and Dev/Test Data Sets:
(in reverse chronological order)


Model training done on AWS Amazon Sagemaker:
Cost of Sagemaker ml.p2.xlarge
storage: $0.10/gig/month = $5 / month for 50 gigs
compute: $1.26/hour if notebook instance is in service, otherwise Stop


To do:
Investigate other METRICS and different optimization parameters
Add examples which have music as a background


3/20/2020
Create a new training set 2c (similar to 2a). Mix a new hand labeled set in with this
and train again on Sagemaker, batches of 100, 30 epochs. 
my_model18_14002c_30e_100b_hl1and2_sagem

Test this new model on a third hand labeled dev set and evaluate performance of 
this model vs. my_model17_2a (best model so far)


3/10/2020
Models are performing very well on test sets that are similar to the training sets
(synthesized using "Hey Joe" and other words, overlaid on backgrounds) but not
so well on real world recordings which are hand labeled. 

Test background corrections used in the synthetic training set (remove background
correction and see if this works better). 

Model training on training data which did NOT have bg correction seems 
to be working a lot worse (1400_2b_no_bg_corr.npy)

Other issues: The presence of the activate word "Hey Joe" in the training examples
was 0-1 before because of risk of collision (overlap with other words). Re make
the synthetic training set with more activate words per training example. If there
are a lot of "Hey Joe" then limit the number of negative words, in order
to prevent collisions.

The increase of Hey Joe in the training examples seems to have alleviated the problem significantly - 14002a model17 seems the best by spot checking. Bg correction does not seem to be the issue.


Created a new hand labeled dev set (X_hand_label_train2.npy) and use this one
to choose between models 2a vs 2a2b. 2a has better performance (see heyjoe_test.py)

Increasing number of activate words per training example seems to help the most.

The training set (with higher number of activates but keeping the original background correction) is X14002a.npy, Y14002a.npy


3/9/2020
Begin training using AWS Amazon Sagemaker

GPU: Sagemaker, finally working, see models trained on there. Not much faster when 
mini batch size = 10, but once batch size = 200 or 100, much much faster than my computer, pretty cool to see the GPU optimization for large batch sizes


NOMENCLATURE of Model names:

The number tells the lineage - my_model17 was trained using my_model_16 as a starting point.  We have a few different 17s, so the 18s were trained on different 17s, but I tried to make notes on #epochs, mini batch size, and training set used when naming the model. 

When _sagem at the end of the Model Name, then it means the model was trained using an Amazon Sagemaker instance (otherwise model was trained on my laptop).



2/29/2020-3/1/2020

my_model7.h5 is the result of training on X1400a-e.npy
A good starting point for new training of models. 

my_model8.h5 is the result of training on X2800 (which I constructed similar to X1400a-e, but I don't quite remember the parameters) and it was interrupted and the 
Python interpreter took up again in the 20th epoch. 

NEXT STEP: Add to the training set a real world, hand labeled set of dev set type examples. Use my spectrogram printing code (disp_wav.py), and zoom in using xlim to identify quickly where the "Hey Joe" ends in real world examples. In this way, 
I hand labeled 25 files. 

Use a part of these in training, use the rest in development and testing.

Starting with my_model8.h5 I created my_model9_hand_label25.h5

I noticed this performed less well on the train.wav (created example), and still no good on the dev set real world Hey Joe recordings. Not enough data and training cycles. 

Try again, start with my_model9_hand_label25, use a data set X1400a + 25 hand labeled data sets, and train again with batch size of 10, and 10 epochs, and see how we do.

my_model10_1400a_plushandlabel25.h5

Take my_model10... and add in 1400b, but the same 25 training examples hand labeled real world ones

Performance maybe slightly improved and predictions are 0.11 instead of 0.0003 in the range of the trigger word.

Used 10 epochs until 1400d. 

Then trained for 30 epochs: my_model13 was trained on 30 epochs
any better? YES. The positions that should be 1, are now 0.22, and the rest are 0.02 on the test/dev examples.

my_model14 was also 30 epochs

my_model15 was 30 epochs on 1400a

my_model14 and my_model16 were both the best with my_model17 having less good
(spot checking on hand labeled examples which were not used in training) - use a dev set and choose the best one after a few more training sessions



2/26/2020
Added 4 more backgrounds for a total of 14 backgrounds (these backgrounds are from real world recordings of us talking and so on). The remaining of these recordings will be used for a dev set. 

Total of 14 backgrounds, and therefore recent training data is 1400 examples per set



2/24/2020:
Noticed a huge bug, which is I had forgotten to remove the random seed fixed, in order for testing (and originally for the Coursera grader) in one of the functions I used from
my programming assignment. This means the training examples are not random, and real 
learning was not happening. Delete models and start over. Remake all training sets. 


*Also number of backgrounds increased (I recorded 3 more) so now it's 10 backgrounds, and 1000 examples if I do 100 per background


2/22/2020 evening is when I switched all recordings over to 44.1kHz (9:30 pm). Previous Training Data wav files were at 16 kHz if they were from my phone, and 44.1 if they were downloaded from the internet.


2/10/2020 

my_model1 was trained using: 
1) a new model which I created to match the architecture used in the one that
Coursera trained on a GPU for a few days, but the Coursera one was trained on a different trigger word. 
2) Weights from the Coursera model trained on a different trigger/activate word (tr_model.h5)
3) Several epochs of further training using my examples which were labeled according to the new trigger word (Hey Joe). These examples are loaded from X700.npy and Y700.npy

my_model2 was trained for another 10 epochs

my_model3 was trained using some new backgrounds from real world scenarios

my_model4 was trained using some examples which contained 44.1 kHz activates and backgrounds (my_model3 was trained on 16 kHz examples primarily). 


Note: originally I had directly loaded the Coursera model and run it on new examples with new activate word "Hey Joe", but the dropout rate is too high (0.8) as the argument to  Dropout layer in Keras changed from keep_prob to dropout rate (from the Coursera version to the version of Python/Tensorflow/Keras I installed on my computer).
So I recreated the whole network architecture and only loaded the weights from my Coursera
problem set model, to have transfer learning. 


*****


heyjoe_model<n>.py
Code I wrote to create the Speech Recognition sequence model using GRU layers in Keras, as
well as Dropout regularization and conv 1D layer. Load weights from the Coursera model I 
wrote in the problem set, which Coursera trained on a GPU. These weights are from a network with same architecture, but trained on the activate word "Activate" 
(not "Hey Joe").

Use transfer learning, to initialize my model with these weights, and then learn for
several epochs on examples I created above, where the activate word is "Hey Joe".
Save model to disk at the end.

Use also several real world examples of Hey Joe, and instructions to Spotify, 
and hand label those. This dev set is partially used to test different models, 
and also partially mixed into the training set (a different subset from the 
ones used in testing). 



heyjoe_create_examples.py:
Code I wrote to create HeyJoe activate word containing examples, examples also
contain negatives. After 700-1400 examples have been created, they are saved to disk
in X700.npy and a corresponding Y700.npy. This code  uses the helper functions below.



heyjoe_helper_functions.py:

Code that I wrote for the Coursera Problem set / Programming Assignment for 
Trigger Word Detection. Contains the code to create synthetic training examples from
activates, negatives and backgrounds



td_utils.py:

4 functions written by Coursera staff to be used in the programming assignment for 
Trigger Word Detection. Contains only a few functions which I use in Hey Joe -

graph_spectrogram to get the spectrogram x for a .wav file

load_raw_audio() which loads all the audio files as Pydub Audiosegments and
ready to be turned into spectrograms which are then used as the input to the
machine learning algorithm. I modified this function slightly for Hey Joe use. 



heyjoe.py
Eventually write code to listen through the microphone and check intervals for Hey Joe.
If we hear the trigger word, then we should use Google Cloud Speech Recognition to 
recognize what is said immediately afterwards, and then send that output to Spotify 
Note: after running the models and examining/spot checking several real world examples, it would make sense to send a few seconds worth of the Speech recording BEFORE the trigger
word detection labels to Google Cloud Speech Recognition too (as the model I trained
can be a bit delayed in the labels, especially if Hey Joe Play is uttered in one
single string by the user. 




 